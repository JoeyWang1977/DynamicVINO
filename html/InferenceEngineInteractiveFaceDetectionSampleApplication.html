<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>My Project: Interactive Face Detection Sample</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">My Project
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Interactive Face Detection Sample </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This sample showcases Object Detection task applied for face recognition using sequence of neural networks. Async API usage can improve overall frame-rate of the application, because rather than wait for inference to complete, the app can continue doing things on the host, while accelerator is busy. Specifically, this demo keeps three parallel infer requests for Age Gender Head Pose and Emotions detection that run simultaneously.</p>
<p>Other demo objectives are:</p><ul>
<li><a class="el" href="classVideo.html">Video</a> as input support via OpenCV</li>
<li>Visualization of the resulting face bounding boxes from Face Detection network</li>
<li>Visualization of age gender, head pose and emotion recognition information for each detected face</li>
<li>OpenCV is used to draw resulting bounding boxes, labels, etc, so you can copy paste this code without need to pull Inference Engine samples helpers to your app</li>
</ul>
<h3>How it works</h3>
<p>On the start-up the application reads command line parameters and loads one, two, three or four networks depending on -d... options family to the Inference Engine. Upon getting a frame from the OpenCV's VideoCapture it performs inference of frame detection network, then performs three simultaneous inferences using Age Gender, Head Pose and Emotions detection networks (if those specified in command line) and displays the results.</p>
<p>New "Async API" operates with new notion of the "Infer Request" that encapsulates the inputs/outputs and separates <em>scheduling and waiting for result</em>, next section. And here what makes the performance look different:</p><ol type="1">
<li>In the default ("Sync") mode the frame is captured and then immediately processed, below in pseudo-code: <div class="fragment"><div class="line"><span class="keywordflow">while</span>(<span class="keyword">true</span>) {</div><div class="line">    capture frame</div><div class="line">    populate FaceDetection InferRequest</div><div class="line">    wait <span class="keywordflow">for</span> the FaceDetection InferRequest</div><div class="line">    populate AgeGender InferRequest <span class="keyword">using</span> dyn batch technique</div><div class="line">    populate HeadPose InferRequest <span class="keyword">using</span> dyn batch technique</div><div class="line">    populate EmotionDetection InferRequest <span class="keyword">using</span> dyn batch technique</div><div class="line">    wait AgeGender</div><div class="line">    wait HeadPose</div><div class="line">    wait EmotionDetection</div><div class="line">    display detection results</div><div class="line">}</div></div><!-- fragment --> So, this is rather reference implementation, where the new Async API is used in the serialized/synch fashion.</li>
</ol>
<h2>Running</h2>
<p>Running the application with the <code>-h</code> option yields the following usage message: </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;./interactive_face_detection -h</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;InferenceEngine: </div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;    API version ............ &lt;version&gt;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;    Build .................. &lt;number&gt;</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;interactive_face_detection [OPTION]</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;Options:</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;    -h                         Print a usage message.</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;    -i &quot;&lt;path&gt;&quot;                Optional. Path to an video file. Default value is &quot;cam&quot; to work with camera.</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;    -m &quot;&lt;path&gt;&quot;                Required. Path to an .xml file with a trained face detection model.</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;    -m_ag &quot;&lt;path&gt;&quot;             Optional. Path to an .xml file with a trained age gender model.</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;    -m_hp &quot;&lt;path&gt;&quot;             Optional. Path to an .xml file with a trained head pose model.</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;    -m_em &quot;&lt;path&gt;&quot;             Optional. Path to an .xml file with a trained emotions model.</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;      -l &quot;&lt;absolute_path&gt;&quot;     Required for MKLDNN (CPU)-targeted custom layers.Absolute path to a shared library with the kernels impl.</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;          Or</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;      -c &quot;&lt;absolute_path&gt;&quot;     Required for clDNN (GPU)-targeted custom kernels.Absolute path to the xml file with the kernels desc.</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;    -d &quot;&lt;device&gt;&quot;              Specify the target device for Face Detection (CPU, GPU, FPGA, or MYRIAD). Sample will look for a suitable plugin for device specified.</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;    -d_ag &quot;&lt;device&gt;&quot;           Specify the target device for Age Gender Detection (CPU, GPU, FPGA, or MYRIAD). Sample will look for a suitable plugin for device specified.</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;    -d_hp &quot;&lt;device&gt;&quot;           Specify the target device for Head Pose Detection (CPU, GPU, FPGA, or MYRIAD). Sample will look for a suitable plugin for device specified.</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;    -d_em &quot;&lt;device&gt;&quot;           Specify the target device for Emotions Detection (CPU, GPU, FPGA, or MYRIAD). Sample will look for a suitable plugin for device specified.</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;    -n_ag &quot;&lt;num&gt;&quot;              Specify number of maximum simultaneously processed faces for Age Gender Detection (default is 16).</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;    -n_hp &quot;&lt;num&gt;&quot;              Specify number of maximum simultaneously processed faces for Head Pose Detection (default is 16).</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;    -n_em &quot;&lt;num&gt;&quot;              Specify number of maximum simultaneously processed faces for Emotions Detection (default is 16).</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;    -no_wait                   No wait for key press in the end.</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;    -no_show                   No show processed video.</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;    -pc                        Enables per-layer performance report.</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;    -r                         Inference results as raw values.</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;    -t                         Probability threshold for detections.</div></div><!-- fragment --><p>Running the application with the empty list of options yields the usage message given above and an error message. You can use the following command to do inference on a GPU with an example pre-trained GoogleNet based SSD* available at <a href="https://software.intel.com/file/609199/download:">https://software.intel.com/file/609199/download:</a> </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;./interactive_face_detection -i &lt;path_to_video&gt;/inputVideo.mp4 -m &lt;path_to_model&gt;/ssd.xml -d GPU</div></div><!-- fragment --><p> Notice that the network should be converted from the Caffe* (*.prototxt + *.model) to the Inference Engine format (*.xml + *bin) first, by use of the ModelOptimizer tool (<a href="https://software.intel.com/en-us/articles/OpenVINO-ModelOptimizer">https://software.intel.com/en-us/articles/OpenVINO-ModelOptimizer</a>).</p>
<h3>Sample Output</h3>
<p>The sample uses OpenCV to display the resulting frame with detections (rendered as bounding boxes and labels, if provided). In the default mode the sample reports</p><ul>
<li><b>OpenCV time</b>: frame decoding + time to render the bounding boxes, labels, and displaying the results.</li>
<li><b>Face Detection time</b>: inference time for the face Detection network.</li>
</ul>
<p>If Age Gender Head Pose or Emotion detections are enabled the additional info below is reported also:</p><ul>
<li><b>Age Gender + Head Pose + Emotions Detection time</b>: combined inference time of simultaneously executed age gender, head pose and emotion recognition networks.</li>
</ul>
<h2>See Also</h2>
<ul>
<li>Using Inference Engine Samples </li>
</ul>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
